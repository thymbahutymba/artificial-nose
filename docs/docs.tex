\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{hyperref}
\usepackage{listings}

\title{Artificial Nose}
\author{Luca Belluardo e Andrea Stevanato}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
In this project a real-time application is developed to recognize smells from an
artificial nose. The sensor used for the application is an air quality gas 
sensor.

The rest of the documentation is structured in the following way: in section
2 the tasks are explained one at a time, in the section 3...

\section{The tasks}
In our application we have 5 periodic tasks (Figure \ref{tdiagram}): graphic
task, sensor task, neural network task (made with Tensorflow), keyboard task
and the store image task.

\begin{figure}[!b]
    \includegraphics[width=\textwidth]{diagram.pdf}
    \caption{Task diagram}
    \label{tdiagram}
\end{figure}

The main function sets everything up for the tasks, except for the store
image task. The keyboard task is in charge to activate the store image task
when the \texttt{ENTER} key is pressed. If the store image task is already in
execution and the \texttt{ENTER} key is pressed this it's terminated.
Before start the store image task it's possible to write the name of the
directory in which the images will be saved; if no name it's writed the
images will be saved into \textit{image\_neural\_network} directory.

The sensor is readed by an Arduino M0 pro; the sampled data readed by arduino
are sent via the serial port to our application and readed by the sensor
task. All the tasks are terminated by the main when the user presses the
\texttt{ESC} key.

\subsection{Main function}
In the main function [\ref{main}] all the tasks, except the store image task,
are started and the mutexes initialized. The mutexes are three, one for the
buffer that contains the values readed from the sensor, one for the results
given by the neural network and one for the buffer that contains the keyboard
input. The main also starts allegro and waits for the termination of the
keyboard task. Once the keyboard task terminates the main cancels all other
task and wait for their termination.

\begin{algorithm}[b]
\caption{Main}
\label{main}

\begin{algorithmic}
\State $T\gets$ \textit{tasks to be started}
\State Mutexes and allegro initialization
\For{$t \in T$}
    \State start $t$
\EndFor

\Loop{ \textit{wait for termination of keyboard task}}
\EndLoop

\For{$t \in T$} 
    \State cancel and join $t$
\EndFor

\end{algorithmic}
\end{algorithm}

\subsection{Graphic Task}

The graphic task [\ref{graphic}] prints the interface (Figure
\ref{interface}) of our application. The interface is divided into different
areas which contains for each one: the graph, the image, the results, the
legend, the current values and the current status (\texttt{SAVING} or
\texttt{WRITING}) followed by, if present, the keyboard input.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/interface.png}
    \caption{Interface of application}
    \label{interface}
\end{figure}

\begin{algorithm}[H]
\caption{Graphic task}
\label{graphic}

\begin{algorithmic}
\State $p\gets$ \textit{task period}
\State set activation task
\State draw interface background

\Loop
\State draw graph
\State draw image
\State draw results given by neural network
\State draw current values readed from sensor
\State draw keyboard input
\State wait for next activation
\EndLoop

\end{algorithmic}
\end{algorithm}

\subsubsection*{Graph}
The graph (Figure \ref{graph}) is made with the values sampled from the 
sensor. These values are plotted with two different colors: red for the $CO2$
and green for the $tVOC$. The graph contains at most $N$ readings of both values.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.60]{images/graph.png}
    \caption{Graph }
    \label{graph}
\end{figure}

\subsubsection*{Image}
The image (Figure \ref{image}) is made with the last $N$ values sampled from
the sensor. The allegro color mode is set to 15-bit. In the 15-bit mode each
color is represented by 5-bit.

The sensor samples two data, the CO2 and the tVOC. Each value is a 15-bit
number and so we represent the values readed as colors in 15-bit. The image
is divided in two parts, left and right. In the left side we draw the CO2
and in the right the tVOC. Even if each value could be potentially from $0$ to 
$2^{16}$ the CO2 value is between $400$ and $8192$ and the tVOC value is between
$0$ and $1187$. These infomations are taken from the datasheet of sensor.

Whenever a new pair of values are readed from the sensor, the image is moved
one line below, removing one line at the bottom of the image and adding the
new line, which contains the new values, on the top of the image.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.60]{images/image.png}
    \caption{Image}
    \label{image}
\end{figure}

\subsubsection*{Results}
This area shows the results (Figure \ref{results}) of neural network having
the current image as input. The lines represent the classes for which the
neural network was trained and the values are the neural network output.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.60]{images/results.png}
    \caption{Result}
    \label{results}
\end{figure}

\subsubsection*{Current values}
This area shows the current values (Figure \ref{values}) sampled from the sensor.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.75]{images/values.png}
    \caption{Current values}
    \label{values}
\end{figure}

\subsubsection*{Current status}
This area (Figure \ref{save_write}) gives the information about the current
mode, printed on the left side; on the right side there is the name of the
directory in which the image are saved.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.75]{images/saving.png}
    \includegraphics[scale=0.75]{images/writing.png}
    \caption{Saving and writing mode}
    \label{save_write}
\end{figure}

\subsection{Sensor task}
The sensor task [\ref{sensortask}] reads the values from the arduino which
sends on serial port the values taken from the sensor. The readed values are
stored into an array and used by the graphic task to draw the image and the
graph; the current readed values are also standalone printed by the graphic
task.

\begin{algorithm}[H]
\caption{Sensor task}
\label{sensortask}

\begin{algorithmic}
\State $p\gets$ \textit{task period}
\State initialization $data\_q$
\State initialization serial port
\State set activation task

\Loop
\State $data\_q\gets data\_q$ + values readed from sensor
\State wait for next activation
\EndLoop

\end{algorithmic}
\end{algorithm}

\subsection{Neural network task}
The neural network task [\ref{nntask}] recognizes the smells using as input the
current image created with the values sampled by the sensor.

\begin{algorithm}[H]
\caption{Neural network task}
\label{nntask}

\begin{algorithmic}
\State $p\gets$ \textit{task period}
\State Tensorflow initialization
\State set activation task

\Loop
\State $image\gets$ current image
\State $results\gets$ use neural network with given $image$
\State wait for next activation
\EndLoop

\end{algorithmic}
\end{algorithm}

\subsection{Keyboard task}
The keyboard task [\ref{ktask}] takes input from keyboard and puts it into
\textit{keyboard buffer}. The keyboard buffer is printed by the graphic task
in its area of interface. The string contained into keyboard buffer is the
directory, under \textit{image\_neural\_network}, where the images are saved
by the store image task. The keyboard task can be in two different mode:
\texttt{WRITING} or \texttt{SAVING}. The task is started in \texttt{WRITING}
mode. During this mode it's possible to write the name of the directory in
which the images are saved. The name can contain letters, numbers, minus,
underscore and point; it's also possible to delete the written characters
pressing the \texttt{BACKSPACE} key. Pressing the \texttt{ENTER} key, the
current mode is switched from the \texttt{WRITING} to the \texttt{SAVING}
mode or vice versa. When the \texttt{ESC} key is pressed the keyboard task
terminates causing the closing of our application.

\begin{algorithm}[H]
\caption{Keyboard task}
\label{ktask}

\begin{algorithmic}
\State $p\gets$ \textit{task period}
\State $cur\_mode\gets$ \texttt{WRITING}
\State create \textit{key\_buffer}
\State keyboard initialization
\State set activation task

\Repeat
\State $key\_pressed\gets$ key code from keyboard
\If {$key\_pressed$ == \texttt{ENTER}}
    \If {$cur\_mode$ == \texttt{WRITING}}
    \State $cur\_mode\gets$ \texttt{SAVING}
    \State start store image task
    \Else
    \State $cur\_mode\gets$ \texttt{WRITING}
    \State stop store image task and clean key\_buffer
    \EndIf
\ElsIf {$cur\_mode$ == \texttt{WRITING}}
    \If {$key\_pressed$ equal to letter, number, minus or point \textbf{and} \textit{key\_buffer} not full}
        \State \textit{key\_buffer} $\gets$ \textit{key\_buffer} + $key\_pressed$ 
    \ElsIf {\textit{key\_buffer} == \texttt{BACKSPACE} \textbf{and} \textit{key\_buffer} not empty}
        \State remove last element from \textit{key\_buffer}
    \EndIf
\EndIf

\Until {$key\_pressed$ != \texttt{ESC}}

\end{algorithmic}
\end{algorithm}

\subsection{Store image task}
The store image task [\ref{sitask}] is activated/terminated by keyboard task
when the \texttt{ENTER} key is pressed. Once the task is activated the image
are saved every $300$ milliseconds. The images saved by this task are used to
train the neural network for the recognizing of smells.

\begin{algorithm}[H]
\caption{Store image task}
\label{sitask}

\begin{algorithmic}
\State $p\gets$ \textit{task period}
\State $dir\gets$ \textit{path to directory where images are saved}
\State set activation task

\Loop
\State save image to $dir$
\State wait for next activation
\EndLoop

\end{algorithmic}
\end{algorithm}

\subsection{Scheduling}
In our application a task table (Listing \ref{ttable}) was created containing
all the task that have to be started by the main function. The parameters
that characterize a task are respectively: thread identifier, function to be
execute, priority, period and deadline miss. At the beginning the thread
identifier is set to $-1$, once the task is activated the thread identifier
is updated. In case of deadline misses the application increments the
corresponding value on the task table. The real time scheduling algorithm
chosen is \texttt{SCHED\_RR}. The deadline corresponds with the period.

\begin{lstlisting}[caption={Task table}, captionpos=b, label={ttable}]
Task task_table[] = {
    {-1, store_image_task, 20, 1000, 0},
    {-1, read_from_sensor_task, 30, 300, 0},
    {-1, graphic_task, 30, 50, 0},
    {-1, neural_network_task, 25, 1500, 0},
    {-1, keyboard_task, 30, 50, 0}
};
\end{lstlisting}

\subsection{Count deadline}

\section{Neural network}
Regarding the neural network we used Tensorflow, an open-source software 
library for dataflow programming across a range of tasks. 

For training the neural network was used a python script
\href{https://www.tensorflow.org/hub/tutorials/image\_retraining}{retrain}
provided by Tensorflow. In this file a lot of configurations are possible. In
our application we use the default configurations and choose only the number
of training steps.

\section{The results}

\section{Conclusions}

\end{document}